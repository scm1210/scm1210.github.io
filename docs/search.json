[
  {
    "objectID": "CV.html",
    "href": "CV.html",
    "title": "CV",
    "section": "",
    "text": "Department of Psychology\nPrinceton University\nsm9518@princeton.edu\n\n\n\nPrinceton University (2024-Present)\nPh.D.¬†in Psychology\nAdvisor: Dr.¬†Erik Nook\nTexas State University (2019-2022)\nM.A.¬†in Psychological Research\nAdvisor: Dr.¬†Randall Osborne\nSouthwestern University (2015-2019)\nB.A. in Psychology (Minor: Spanish)\n\n\n\n\n* Denotes Shared First Authorship\nMesquiti, S., Cosme, D., Nook, E.C., Falk E.B., Burns S. (Under Revision). Predicting Psychological and Subjective Well-being through Language-based Assessments of Well-being.\nMesquiti, S.,* Seraj, S.,* Weyland, A. H., Ashokkumar, A., Boyd, R. L., Mihalcea, R., & Pennebaker, J. W. (2025). Analysis of social media language reveals the psychological interaction of three successive upheavals. Scientific Reports, 15(1), 5740. DOI.\nKang, Y., Mesquiti, S., Baik, E.S., & Falk, E. B. (2024). Empathy and Helping: The Role of Affect in Response to Others‚Äô Suffering. Scientific Reports, 15, 3256 DOI.\nMesquiti, S., Seraj, S. (2023). The Psychological Impacts of the COVID-19 Pandemic on Business Leadership. PLOS One. DOI\n\n\n\n\n\nKang, Y., Mesquiti, S. & Falk, E. B. (in prep). The Effect of Compassion Training on Emotional Support Giving.\nMesquiti, S. & Nook, E.C. (in prep.) The Implication of Artificial Intelligence on Mental Health.\nMesquiti, S., Stade E. C., Hull, T.D., Nook, E. C. (in prep.) Tracking Shifts in the Latent Meaning of ‚ÄúI‚Äù and Its Connection to Mental Health Outcomes in a Large Therapy Dataset.\n\n\n\n\n\n\n2025: Princeton University Data Driven Social Science Graduate Fellowship ($1,200)\n2025: Princeton University Data Driven Social Science: Data-Driven Approaches to Building Equitable Language-Based Mental Health Assessments ($4,283)\n2025: New Jersey Health Foundation: Investigating Racial Equity of Psycholinguistic Measures of Mental Health (PI: Erik C. Nook; $34,867; # PC 42-25)\n2022: Northwestern University Kellogg School of Management Behavioral Research Fellowship (Finalist [Declined]; $35,000)\n2020: Texas State University Thesis Research Support Fellowship ($1,070)\n\n\n\n\n\n\n2025: Princeton University Data Driven Social Science Graduate Fellowship\n2024-25: Princeton University William G. Bowen Merit Fellowship\n2020-21: Texas State University Graduate College of Liberal Arts Scholarship\n2021: Masters in Psychological Research Graduate Competitive Scholarship\n2019: Texas State University Graduate College of Education Scholarship\n2015: Southwestern University Mood Scholar\n\n\n\n\n\n\n2025: Tracking Shifts in the Latent Meaning of ‚ÄúI‚Äù and Its Connection to Mental Health Outcomes in a Large Therapy Dataset. Social Psychology Seminar, Princeton University, Princeton, NJ.\n2022: Within-and between-person effects of autonomous motivation on goal pursuit. Duckworth Lab, Princeton University.\n2021: The whole truth and nothing but the truth: an analysis of the variability of prosocial lying in the Netherlands and the United States. Texas State University Psychology Department Brown Bag.\n2021: The truth about prosocial lying: Cross-cultural differences in prosocial lying. Southwestern Psychological Association (Virtual).\n\n\n\n\n\n* Denotes Undergraduate Mentored\n\nMesquiti, S. C., Nook, E. (2024, March). Investigating Racial Sensitivity in Language-Based Assessments of Mental Health. Poster presented at the annual meeting for the Society for Affective Science.\nMesquiti, S. C., Cosme, D., Nook, E., Falk E., Burns S. (2025, February). Predicting Well-being with Language-based Assessments. Poster presented at the annual meeting for the Society for Personality and Social Psychology.\nMesquiti, S. C., Burns S., Cosme, D., Falk E. (2024, February). Enhancing Psychological Well-being Prediction Through Natural Language Analysis. Poster presented at the annual meeting for the Society for Personality and Social Psychology.\nMesquiti, S. C., Mobasser, A., Falk, E., Pfeifer, J. H., & Cosme, D (2023, February). Within-and between-person effects of autonomous motivation on goal pursuit. Poster submitted to the annual meeting for the Society for Personality and Social Psychology.\nSpehar, A.,* Muzekari, B., Butler, T. B., Mesquiti, S.C., Cosme, D., Falk, E. (2022, August). Relating Collective and Self-Focus Language in Social Support with Self-Reported Depression. Poster presented at the annual University of Pennsylvania MindCORE student show case. Philadelphia, Pa. Github\nAndrews, M. E., Cooper, N., Paul, A., Johnson, D., Muzekari, B., Mesquiti, S.C., Torres, O., Resnick, A., Scholz, C., Mattan, B., Barnet, I., Henriksen, L., Strasser, A., & Falk, E. B. (2023, May). Compounding effect of microaggressions and exposure to tobacco advertising on stress and smoking. Annual conference of the International Communication Association, Toronto, Ontario, Canada.\nSantana, C.,* Mesquiti, S.C., Carreras-Tartak, J., Kang, Y., Falk, E. (2022, August). Relating Collective and Self-Focus Language in Social Support with Self-Reported Depression. Poster presented at the annual University of Pennsylvania MindCORE student show case. Philadelphia, Pa.\nWoolfolk, Z*., Cosme, D., Butler, T., Carreras-Tartak, J., Mesquiti, S.C., Kang, Y., Falk, E. (2022, August). Racial Homophily in Emotion Sharing Network. Poster presented at the annual University of Pennsylvania MindCORE student show case. Philadelphia, Pa.\nMesquiti, S.C. (2022, April). Exploring Cognitive Language of CEOs during the COVID-19 Pandemic Over Time and its Connection to Decision Processing. Poster presented at the annual Texas State University Psychology Department Showcase. San Marcos, Tx.\nMesquiti, S.C., Tsai, J. L., Marion, J., Olivarez, O., Blackburn, K., Durland, M. (2022, February). The linguistic lifespan of a CEO: Exploring the way cognitive language unfolds over time and its connection to decision processing. Poster presented at the annual meeting for the Society for Personality and Social Psychology.\nHaskard-Zolnierek, K., Mesquiti, S.C., & Snyder, M. (2022, February). Associations between patient satisfaction and physician and nurse word use. Poster presented at the annual meeting for the Society for Personality and Social Psychology (virtual).\nMesquiti, S.C., Kok, R., Clegg, J. M., Warnell, K. R. (2021, April). The truth behind prosocial lies: A linguistic analysis of lying to be polite. Poster presented at the annual Texas State University Psychology Department Showcase. San Marcos, Tx.\nMesquiti, S.C., Domer, K., Warnell, K. R., Clegg, J. M. (2021, February). More than a disappointing gift: Examining variability in when and how we prosocially lie. Poster presented at the annual meeting for the Society for Personality and Social Psychology (virtual).\nDomer, K., Mesquiti, S.C., Warnell, K. R., Clegg, J. M. (2021, February). More than a social norm: Examining who we lie to and what we lie about. Poster presented at the annual meeting for the Society for Personality and Social Psychology (virtual).\nMesquiti, S.C. (2019, April). Internship at the Central Texas Treatment Center. Poster presented at Southwestern University Creative Works Symposium, Georgetown, Tx.\n\n\n\n\n\n\nEmi Yun | Thesis Student | Princeton University (2024-Present)\nArden Spehar | Summer MindCORE REU Student | University of Pennsylvania (2022)\nCarlos Santana | Summer MindCORE REU Student | University of Pennsylvania (2022)\n\n\n\n\n\n\nEmily Falk\nProfessor of Communication, Psychology, Marketing, and OID (Operations, Informatics, and Decisions), Vice Dean of the Annenberg School for Communication, University of Pennsylvania\nefalk@falklab.org\nJames Pennebaker\nProfessor Emeritus of Psychology, The University of Texas at Austin\npennebaker@utexas.edu\nErik Nook\nAssistant Professor of Psychology, Princeton University\nenook@princeton.edu"
  },
  {
    "objectID": "CV.html#education",
    "href": "CV.html#education",
    "title": "CV",
    "section": "",
    "text": "Princeton University (2024-Present)\nPh.D.¬†in Psychology\nAdvisor: Dr.¬†Erik Nook\nTexas State University (2019-2022)\nM.A.¬†in Psychological Research\nAdvisor: Dr.¬†Randall Osborne\nSouthwestern University (2015-2019)\nB.A. in Psychology (Minor: Spanish)"
  },
  {
    "objectID": "CV.html#publications",
    "href": "CV.html#publications",
    "title": "CV",
    "section": "",
    "text": "* Denotes Shared First Authorship\nMesquiti, S., Cosme, D., Nook, E.C., Falk E.B., Burns S. (Under Revision). Predicting Psychological and Subjective Well-being through Language-based Assessments of Well-being.\nMesquiti, S.,* Seraj, S.,* Weyland, A. H., Ashokkumar, A., Boyd, R. L., Mihalcea, R., & Pennebaker, J. W. (2025). Analysis of social media language reveals the psychological interaction of three successive upheavals. Scientific Reports, 15(1), 5740. DOI.\nKang, Y., Mesquiti, S., Baik, E.S., & Falk, E. B. (2024). Empathy and Helping: The Role of Affect in Response to Others‚Äô Suffering. Scientific Reports, 15, 3256 DOI.\nMesquiti, S., Seraj, S. (2023). The Psychological Impacts of the COVID-19 Pandemic on Business Leadership. PLOS One. DOI"
  },
  {
    "objectID": "CV.html#works-in-progress",
    "href": "CV.html#works-in-progress",
    "title": "CV",
    "section": "",
    "text": "Kang, Y., Mesquiti, S. & Falk, E. B. (in prep). The Effect of Compassion Training on Emotional Support Giving.\nMesquiti, S. & Nook, E.C. (in prep.) The Implication of Artificial Intelligence on Mental Health.\nMesquiti, S., Stade E. C., Hull, T.D., Nook, E. C. (in prep.) Tracking Shifts in the Latent Meaning of ‚ÄúI‚Äù and Its Connection to Mental Health Outcomes in a Large Therapy Dataset."
  },
  {
    "objectID": "CV.html#funding",
    "href": "CV.html#funding",
    "title": "CV",
    "section": "",
    "text": "2025: Princeton University Data Driven Social Science Graduate Fellowship ($1,200)\n2025: Princeton University Data Driven Social Science: Data-Driven Approaches to Building Equitable Language-Based Mental Health Assessments ($4,283)\n2025: New Jersey Health Foundation: Investigating Racial Equity of Psycholinguistic Measures of Mental Health (PI: Erik C. Nook; $34,867; # PC 42-25)\n2022: Northwestern University Kellogg School of Management Behavioral Research Fellowship (Finalist [Declined]; $35,000)\n2020: Texas State University Thesis Research Support Fellowship ($1,070)"
  },
  {
    "objectID": "CV.html#fellowships",
    "href": "CV.html#fellowships",
    "title": "CV",
    "section": "",
    "text": "2025: Princeton University Data Driven Social Science Graduate Fellowship\n2024-25: Princeton University William G. Bowen Merit Fellowship\n2020-21: Texas State University Graduate College of Liberal Arts Scholarship\n2021: Masters in Psychological Research Graduate Competitive Scholarship\n2019: Texas State University Graduate College of Education Scholarship\n2015: Southwestern University Mood Scholar"
  },
  {
    "objectID": "CV.html#invited-talks",
    "href": "CV.html#invited-talks",
    "title": "CV",
    "section": "",
    "text": "2025: Tracking Shifts in the Latent Meaning of ‚ÄúI‚Äù and Its Connection to Mental Health Outcomes in a Large Therapy Dataset. Social Psychology Seminar, Princeton University, Princeton, NJ.\n2022: Within-and between-person effects of autonomous motivation on goal pursuit. Duckworth Lab, Princeton University.\n2021: The whole truth and nothing but the truth: an analysis of the variability of prosocial lying in the Netherlands and the United States. Texas State University Psychology Department Brown Bag.\n2021: The truth about prosocial lying: Cross-cultural differences in prosocial lying. Southwestern Psychological Association (Virtual)."
  },
  {
    "objectID": "CV.html#conference-presentations",
    "href": "CV.html#conference-presentations",
    "title": "CV",
    "section": "",
    "text": "* Denotes Undergraduate Mentored\n\nMesquiti, S. C., Nook, E. (2024, March). Investigating Racial Sensitivity in Language-Based Assessments of Mental Health. Poster presented at the annual meeting for the Society for Affective Science.\nMesquiti, S. C., Cosme, D., Nook, E., Falk E., Burns S. (2025, February). Predicting Well-being with Language-based Assessments. Poster presented at the annual meeting for the Society for Personality and Social Psychology.\nMesquiti, S. C., Burns S., Cosme, D., Falk E. (2024, February). Enhancing Psychological Well-being Prediction Through Natural Language Analysis. Poster presented at the annual meeting for the Society for Personality and Social Psychology.\nMesquiti, S. C., Mobasser, A., Falk, E., Pfeifer, J. H., & Cosme, D (2023, February). Within-and between-person effects of autonomous motivation on goal pursuit. Poster submitted to the annual meeting for the Society for Personality and Social Psychology.\nSpehar, A.,* Muzekari, B., Butler, T. B., Mesquiti, S.C., Cosme, D., Falk, E. (2022, August). Relating Collective and Self-Focus Language in Social Support with Self-Reported Depression. Poster presented at the annual University of Pennsylvania MindCORE student show case. Philadelphia, Pa. Github\nAndrews, M. E., Cooper, N., Paul, A., Johnson, D., Muzekari, B., Mesquiti, S.C., Torres, O., Resnick, A., Scholz, C., Mattan, B., Barnet, I., Henriksen, L., Strasser, A., & Falk, E. B. (2023, May). Compounding effect of microaggressions and exposure to tobacco advertising on stress and smoking. Annual conference of the International Communication Association, Toronto, Ontario, Canada.\nSantana, C.,* Mesquiti, S.C., Carreras-Tartak, J., Kang, Y., Falk, E. (2022, August). Relating Collective and Self-Focus Language in Social Support with Self-Reported Depression. Poster presented at the annual University of Pennsylvania MindCORE student show case. Philadelphia, Pa.\nWoolfolk, Z*., Cosme, D., Butler, T., Carreras-Tartak, J., Mesquiti, S.C., Kang, Y., Falk, E. (2022, August). Racial Homophily in Emotion Sharing Network. Poster presented at the annual University of Pennsylvania MindCORE student show case. Philadelphia, Pa.\nMesquiti, S.C. (2022, April). Exploring Cognitive Language of CEOs during the COVID-19 Pandemic Over Time and its Connection to Decision Processing. Poster presented at the annual Texas State University Psychology Department Showcase. San Marcos, Tx.\nMesquiti, S.C., Tsai, J. L., Marion, J., Olivarez, O., Blackburn, K., Durland, M. (2022, February). The linguistic lifespan of a CEO: Exploring the way cognitive language unfolds over time and its connection to decision processing. Poster presented at the annual meeting for the Society for Personality and Social Psychology.\nHaskard-Zolnierek, K., Mesquiti, S.C., & Snyder, M. (2022, February). Associations between patient satisfaction and physician and nurse word use. Poster presented at the annual meeting for the Society for Personality and Social Psychology (virtual).\nMesquiti, S.C., Kok, R., Clegg, J. M., Warnell, K. R. (2021, April). The truth behind prosocial lies: A linguistic analysis of lying to be polite. Poster presented at the annual Texas State University Psychology Department Showcase. San Marcos, Tx.\nMesquiti, S.C., Domer, K., Warnell, K. R., Clegg, J. M. (2021, February). More than a disappointing gift: Examining variability in when and how we prosocially lie. Poster presented at the annual meeting for the Society for Personality and Social Psychology (virtual).\nDomer, K., Mesquiti, S.C., Warnell, K. R., Clegg, J. M. (2021, February). More than a social norm: Examining who we lie to and what we lie about. Poster presented at the annual meeting for the Society for Personality and Social Psychology (virtual).\nMesquiti, S.C. (2019, April). Internship at the Central Texas Treatment Center. Poster presented at Southwestern University Creative Works Symposium, Georgetown, Tx."
  },
  {
    "objectID": "CV.html#mentorship",
    "href": "CV.html#mentorship",
    "title": "CV",
    "section": "",
    "text": "Emi Yun | Thesis Student | Princeton University (2024-Present)\nArden Spehar | Summer MindCORE REU Student | University of Pennsylvania (2022)\nCarlos Santana | Summer MindCORE REU Student | University of Pennsylvania (2022)"
  },
  {
    "objectID": "CV.html#references",
    "href": "CV.html#references",
    "title": "CV",
    "section": "",
    "text": "Emily Falk\nProfessor of Communication, Psychology, Marketing, and OID (Operations, Informatics, and Decisions), Vice Dean of the Annenberg School for Communication, University of Pennsylvania\nefalk@falklab.org\nJames Pennebaker\nProfessor Emeritus of Psychology, The University of Texas at Austin\npennebaker@utexas.edu\nErik Nook\nAssistant Professor of Psychology, Princeton University\nenook@princeton.edu"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Steven Mesquiti",
    "section": "",
    "text": "My name is Steven Mesquiti! I‚Äôm a second-year PhD Student in the Department of Psychology at Princeton University advised by Erik Nook.\nI study how we can use Natural Language Processing techniques and Artificial Intelligence to better understand people‚Äôs mental health.\nBefore Princeton, I worked as a Lab Manager for Emily Falk in the Communication Neuroscience Lab at the University of Pennsylvania. Along the way, I have worked with excessively generous scientists like Jamie Pennebaker to answer questions at the nexus of Computer Science, Computational Linguistics, and Psychology."
  },
  {
    "objectID": "about.html#research-interests",
    "href": "about.html#research-interests",
    "title": "Steven Mesquiti",
    "section": "üß† Research Interests",
    "text": "üß† Research Interests\n\nNatural Language Processing\nMental Health\nLanguage-based Assessments of Mental Health\nArtificial Intelligence"
  },
  {
    "objectID": "about.html#education",
    "href": "about.html#education",
    "title": "Steven Mesquiti",
    "section": "üéì Education",
    "text": "üéì Education\n\n\n\n\n\n\n\n\n\nDegree\nField\nYear(s)\nInstitution\n\n\n\n\nPh.D.\nPsychology\n2024‚ÄìPresent\nPrinceton University\n\n\nM.A.\nPsychological Research\n2019‚Äì2022\nTexas State University\n\n\nB.A.\nPsychology (Minor: Spanish)\n2015‚Äì2019\nSouthwestern University"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Steven Mesquiti",
    "section": "",
    "text": "My name is Steven Mesquiti! I‚Äôm a second-year PhD Student in the Department of Psychology at Princeton University advised by Erik Nook.\nI study how we can use Natural Language Processing techniques and Artificial Intelligence to better understand people‚Äôs mental health.\nBefore Princeton, I worked as a Lab Manager for Emily Falk in the Communication Neuroscience Lab at the University of Pennsylvania. Along the way, I have worked with excessively generous scientists like Jamie Pennebaker to answer questions at the nexus of Computer Science, Computational Linguistics, and Psychology."
  },
  {
    "objectID": "index.html#research-interests",
    "href": "index.html#research-interests",
    "title": "Steven Mesquiti",
    "section": "üß† Research Interests",
    "text": "üß† Research Interests\n\nNatural Language Processing\nMental Health\nLanguage-based Assessments of Mental Health\nArtificial Intelligence"
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "Steven Mesquiti",
    "section": "üéì Education",
    "text": "üéì Education\n\n\n\n\n\n\n\n\n\nDegree\nField\nYear(s)\nInstitution\n\n\n\n\nPh.D.\nPsychology\n2024‚ÄìPresent\nPrinceton University\n\n\nM.A.\nPsychological Research\n2019‚Äì2022\nTexas State University\n\n\nB.A.\nPsychology (Minor: Spanish)\n2015‚Äì2019\nSouthwestern University"
  },
  {
    "objectID": "publications/predicting-psychological-and-subjective-well-being-through-language-based-assessment/index.html",
    "href": "publications/predicting-psychological-and-subjective-well-being-through-language-based-assessment/index.html",
    "title": "Predicting Psychological and Subjective Well-being through Language-based Assessment",
    "section": "",
    "text": "Abstract\nWell-being is often defined in terms of a person‚Äôs comfort, happiness, functioning and flourishing. Scholars distinguish subjective well-being (i.e., perceiving one‚Äôs life as pleasant) from psychological well-being (i.e., perceiving one‚Äôs life as meaningful). Advances in natural language processing have yielded automated assessments of psychological states and traits from language alone, including subjective well-being. However, the strength of these tools for assessing psychological well-being remains unstudied. Across three studies (one preregistered), we examined the strength of language-based assessments of self-reported subjective and psychological well-being components. Participants gave verbal or written responses to queries regarding their satisfaction with life and autonomy, along with questionnaire measures of subjective and psychological well-being. We then tested the strength of contextual word embeddings generated from AI-based transformers applied to verbal responses in predicting self-reported satisfaction with life and psychological well-being. Predictions generated from word embeddings of open-ended assessments correlated significantly with questionnaire measures of corresponding well-being constructs (rs = .16 &lt; r &lt; .63) and they also generalized across well-being components (rs = .15 &lt; r &lt; .50). However, the strength of these relations was lower than previous studies (rs = .72 &lt; r &lt; .85), and sense of autonomy was consistently less predictable than satisfaction with life. These findings demonstrate that although linguistic measures can significantly correlate with one‚Äôs sense of autonomy, it appears to be more challenging to assess than other forms of well-being.\nCitation: Mesquiti, S., Cosme, D., Nook, E. C., Falk, E. B., & Burns, S. (2023). Predicting psychological and subjective well-being through language-based assessment. Preprint."
  },
  {
    "objectID": "publications/empathy-and-helping-the-role-of-affect-in-response-to-others-suffering/index.html",
    "href": "publications/empathy-and-helping-the-role-of-affect-in-response-to-others-suffering/index.html",
    "title": "Empathy and helping: the role of affect in response to others‚Äô suffering",
    "section": "",
    "text": "Abstract\nDecades of research hold that empathy is a multifaceted construct. A related challenge in empathy research is to describe how each subcomponent of empathy uniquely contributes to social outcomes. Here, we examined distinct mechanisms through which different components of empathy‚ÄîEmpathic Concern, Perspective Taking, and Personal Distress‚Äîmay relate to prosociality. Participants (N = 77) watched a prerecorded video of a person sharing an emotional real-life story and provided verbal support in response. The listeners then reported how positive and negative they felt while listening to the story. We found that individuals with greater tendencies to experience Empathic Concern and Perspective Taking felt more positive (e.g., connected, compassionate), whereas those with higher Personal Distress felt more negative (e.g., nervous, anxious) in response to another‚Äôs suffering. We also observed indirect relationships between Empathic Concern / Perspective Taking and the tendency to help others through positive affective responses to the other‚Äôs suffering. These findings build upon the growing literature that distinguishes different components of empathy and their mechanisms that relate to divergent behavioral consequences. Results also highlight the role of positive affect that may motivate prosociality in the face of others‚Äô suffering.\nCitation: Kang, Y., Mesquiti, S., Baik, E. S., & Falk, E. B. (2025). Empathy and helping: the role of affect in response to others‚Äô suffering. Scientific Reports, 15(1), 3256. https://doi.org/10.1038/s41598-025-87221-2"
  },
  {
    "objectID": "posts/Stats-Project/Stats-project.html",
    "href": "posts/Stats-Project/Stats-project.html",
    "title": "Final Project: Prediciting Head to Head Pok√©mon Wins with Multi-level Binary Logistic Regression",
    "section": "",
    "text": "This tutorial will walk you through the process of simulating Pok√©mon battles using the OpenAI API and then analyzing the results using a multi-level binary logistic regression model using a Specification Curve Analysis framework. The main analytic goal is to see which Pokemon stats are most predictive of winning a battle.\nWe are using a multi-level binary logistic regression model given the multiple levels of data we have. Each battle is a unique observation, but each Pok√©mon has multiple stats that are used to predict the outcome of the battle. This means that we need to account for the fact that different Pok√©mon may have different effects on the outcome of the battle. Further, we have to employ a logistic regression framework since our outcome is binary (win/loss)."
  },
  {
    "objectID": "posts/Stats-Project/Stats-project.html#load-libraries-api-key-and-set-model-information",
    "href": "posts/Stats-Project/Stats-project.html#load-libraries-api-key-and-set-model-information",
    "title": "Final Project: Prediciting Head to Head Pok√©mon Wins with Multi-level Binary Logistic Regression",
    "section": "Load Libraries, API Key, and set model information",
    "text": "Load Libraries, API Key, and set model information\nStart by loading in the necessary libraries (and installing them if necessary) and setting up the OpenAI API key. I‚Äôd recommend running this in a separate notebook, as it will take a while to run the ~3000 individual battles. We also set a temperature of 0 to make the model more deterministic.\n\n\n\n\n\n\nüí° It is important to note that you should not share your OpenAI API key with anyone. It is a sensitive piece of information that should be kept private. If you are using a public notebook or sharing your code, make sure to remove or mask your API key before sharing. You can use environment variables or a .env file to store your API key securely.\n\n\n\n\nfrom openai import OpenAI, RateLimitError, APIError, APITimeoutError\nimport pandas as pd \nfrom tqdm.notebook import tqdm\nfrom dotenv import load_dotenv\nimport re\nimport numpy as np\nimport json\nimport argparse\nimport random\nimport time\nimport os\nimport ast\n\nload_dotenv(\"/Users/sm9518/Desktop/Article-Summarizer/.env\") # where i keep my API key... \napi_key = os.getenv(\"OPENAI_API_KEY\")\nif api_key:\n    print(\"API Key loaded successfully!\\n:)\")\nelse:\n    raise ValueError(\"API Key not found.\\nMake sure it is set in the .env file.\")\nmodel=\"gpt-3.5-turbo\" # set model. we dont need anything fancy for this task.\ntemperature=0 # set temp to be rather determinisitic \nSEED = random.seed(42) # set seed for reproducibility"
  },
  {
    "objectID": "posts/Stats-Project/Stats-project.html#load-data-and-sample",
    "href": "posts/Stats-Project/Stats-project.html#load-data-and-sample",
    "title": "Final Project: Prediciting Head to Head Pok√©mon Wins with Multi-level Binary Logistic Regression",
    "section": "Load Data and Sample",
    "text": "Load Data and Sample\nBefore we run the simulations, we have to create our dataset. This can be done by downloading the original kaggle dataset here.\nOnce you‚Äôve done so, we will extract the original 151 Pok√©mon and create a dataset of 20 matchups for each Pok√©mon.\n\ndf = pd.read_csv('/Users/sm9518/Library/CloudStorage/GoogleDrive-sm9518@princeton.edu/My Drive/Classes/Stats-blog/posts/final-project/data/pokedex.csv', index_col=0)\ndf.head()\n\nOG_pokedex = df.iloc[:151].copy() # take the OG 151 pokemon\n\n# build the 20‚Äêmatchups per Pok√©mon\nmatchups = []\nfor challenger in OG_pokedex['name']:\n    pool = [p for p in OG_pokedex['name'] if p != challenger]\n    opponents = random.sample(pool, 20) # give them 20 challengers\n    for opponent in opponents:\n        matchups.append({'challenger': challenger, 'opponent': opponent})\nmatchups_df = pd.DataFrame(matchups)\n\n\n\n# merge challenger metadata\nmatchups_with_meta = (\n    matchups_df\n    .merge(\n        OG_pokedex.add_suffix('_challenger'),\n        left_on='challenger',\n        right_on='name_challenger',\n        how='left'\n    )\n    # drop the redundant name_challenger column if you like\n    .drop(columns=['name_challenger'])\n    # merge opponent metadata\n    .merge(\n        OG_pokedex.add_suffix('_opponent'),\n        left_on='opponent',\n        right_on='name_opponent',\n        how='left'\n    )\n    .drop(columns=['name_opponent'])\n)\n\n# now every row has both challenger_* and opponent_* columns\nmatchups_with_meta.head()"
  },
  {
    "objectID": "posts/Stats-Project/Stats-project.html#hit-the-api-to-simulate-match-ups",
    "href": "posts/Stats-Project/Stats-project.html#hit-the-api-to-simulate-match-ups",
    "title": "Final Project: Prediciting Head to Head Pok√©mon Wins with Multi-level Binary Logistic Regression",
    "section": "Hit the API to Simulate Match-ups",
    "text": "Hit the API to Simulate Match-ups\nOnce we‚Äôve created the dataset, we can use the OpenAI API to simulate the match-ups. In short, for each battle, we will feed the stats of both Pok√©mon and ask GPT to determine the winner. We can then extract and save that data for downstream analyses.\n\n\n\n\n\n\nüí° The API call is rate limited, so we need to be careful about how many requests we send. We will use the tqdm library to show a progress bar and add a sleep time between requests to avoid hitting the rate limit.\nOur prompt is as follows:\n    \"Based on the stats, which Pok√©mon would win a one-on-one battle?\\n\\n\"\n    f\"{p1_stats}\\nVS\\n\\n{p2_stats}\\n\\n\"\n    \"Only respond with the name of the winning Pok√©mon.\"\n\n\n\n\n# Initialize OpenAI client\nclient = OpenAI()\n# ---- Utility Functions ---- #\n\ndef safe_parse_types(val):\n    if isinstance(val, list):\n        return val\n    try:\n        return ast.literal_eval(val)\n    except Exception:\n        return [str(val)]\n\ndef format_pokemon_stats(name, row, suffix):\n    types = safe_parse_types(row[f'type{suffix}'])\n    return (\n        f\"{name.title()}:\\n\"\n        f\"- Type: {', '.join(types)}\\n\"\n        f\"- HP: {row[f'hp{suffix}']}\\n\"\n        f\"- Attack: {row[f'attack{suffix}']}\\n\"\n        f\"- Defense: {row[f'defense{suffix}']}\\n\"\n        f\"- Special Attack: {row[f's_attack{suffix}']}\\n\"\n        f\"- Special Defense: {row[f's_defense{suffix}']}\\n\"\n        f\"- Speed: {row[f'speed{suffix}']}\\n\"\n    )\n\n# ---- API Interaction ---- #\n\ndef get_completion(prompt):\n    messages = [{\"role\": \"user\", \"content\": prompt}]\n    response = client.chat.completions.create(\n        model=model,\n        messages=messages,\n        temperature=temperature\n    )\n    return response.choices[0].message.content.strip()\n\ndef get_response(prompt):\n    try:\n        return get_completion(prompt)\n    except RateLimitError as e:\n        retry_time = getattr(e, 'retry_after', 30)\n        print(f\"Rate limit exceeded. Retrying in {retry_time} seconds...\")\n        time.sleep(retry_time)\n        return get_response(prompt)\n    except APIError as e:\n        print(f\"API error occurred: {e}. Retrying in 30 seconds...\")\n        time.sleep(30)\n        return get_response(prompt)\n    except APITimeoutError as e:\n        print(f\"Request timed out: {e}. Retrying in 10 seconds...\")\n        time.sleep(10)\n        return get_response(prompt)\n    except Exception as e:\n        print(f\"Unexpected error: {e}. Retrying in 10 seconds...\")\n        time.sleep(10)\n        return get_response(prompt)\n\n# ---- Simulate One Battle ---- #\n\ndef simulate_battle(row):\n    p1_stats = format_pokemon_stats(row['challenger'], row, '_challenger')\n    p2_stats = format_pokemon_stats(row['opponent'], row, '_opponent')\n\n    prompt = (\n        \"Based on the stats, which Pok√©mon would win a one-on-one battle?\\n\\n\"\n        f\"{p1_stats}\\nVS\\n\\n{p2_stats}\\n\\n\"\n        \"Only respond with the name of the winning Pok√©mon.\"\n    )\n\n    response = get_response(prompt)\n    return response.lower()\n\n# ---- Run All Simulations ---- #\n\n# This should be your DataFrame containing all matchups\n# matchups_with_meta = pd.read_csv(...)  # Load your data here\n\nresults = []\n\nfor idx, row in tqdm(matchups_with_meta.iterrows(), total=len(matchups_with_meta), desc=\"Simulating battles\"):\n    print(f\"Simulating battle {idx + 1} of {len(matchups_with_meta)}: {row['challenger']} vs {row['opponent']}\")\n    winner = simulate_battle(row)\n    results.append({\n        \"challenger\": row['challenger'],\n        \"opponent\": row['opponent'],\n        \"winner\": winner\n    })\n    time.sleep(1.5)  # Respect rate limits\n\n# ---- Save Results ---- #\n\nresults_df = pd.DataFrame(results)\nmatchups_with_results = matchups_with_meta.merge(\n    results_df,\n    on=[\"challenger\", \"opponent\"],\n    how=\"left\"\n)\nmatchups_with_results.head()\nmatchups_with_results.to_csv(f\"/Users/sm9518/Library/CloudStorage/GoogleDrive-sm9518@princeton.edu/My Drive/Classes/Stats-blog/posts/final-project/data/pokemon_battle_results_{model}_{SEED}_{temperature}.csv\", index=False)\nprint(f\"\\nDone! Winners saved to pokemon_battle_results_{model}_{SEED}_{temperature}.csv.\")"
  },
  {
    "objectID": "posts/Stats-Project/Stats-project.html#take-a-look-at-the-data",
    "href": "posts/Stats-Project/Stats-project.html#take-a-look-at-the-data",
    "title": "Final Project: Prediciting Head to Head Pok√©mon Wins with Multi-level Binary Logistic Regression",
    "section": "Take a look at the data",
    "text": "Take a look at the data\nHere, we are taking a look at a random sample of the data to see if it looks like we expect. We can also use the DT package to create an interactive table that allows us to sort and filter the data.\n\ndf_small |&gt; \n  sample_n(10) |&gt;\n  DT::datatable()"
  },
  {
    "objectID": "posts/Stats-Project/Stats-project.html#visualize-the-distribution-of-the-various-pok√©mon-stats",
    "href": "posts/Stats-Project/Stats-project.html#visualize-the-distribution-of-the-various-pok√©mon-stats",
    "title": "Final Project: Prediciting Head to Head Pok√©mon Wins with Multi-level Binary Logistic Regression",
    "section": "Visualize the distribution of the various Pok√©mon stats",
    "text": "Visualize the distribution of the various Pok√©mon stats\n\nDistribution of Pok√©mon stats\nFrom looking at the density plots we have some interesting insights. For example, we can see that the distribution of the Pok√©mon stats is not normal, and that there are some outliers in the data. We‚Äôll leave them in since we are interested in the relationship between the stats and the outcome of the battle and know this is how the Pokemon appear in the game.\n\ndf_small |&gt; \n  dplyr::select(3:12,-type) |&gt; \n  pivot_longer(cols = everything(), names_to = \"stat\", values_to = \"value\") |&gt; \n  ggplot(aes(x = value, fill = stat)) +\n  geom_density(alpha = 0.7) +\n  facet_wrap(~ stat, scales = \"free\",ncol = 3) +\n  labs(title = \"Distribution of Pok√©mon Stats\", x = \"Value\", y = \"Density\") +\n  scale_fill_manual(values = palette) +\n  plot_aes\n\n\n\n\n\n\n\n\n\n\nComparing Distributions of Pok√©mon stats by outcome\nNow, let‚Äôs look at the distribution of the Pok√©mon stats by winner. This will allow us to see if there are any differences in the different distributions between the winners and losers without running any analyses\n\ndf_small |&gt; \n  dplyr::select(3:12, -type, winner) |&gt; \n  rename(outcome = winner) |&gt; \n  pivot_longer(cols = -outcome, names_to = \"stat\", values_to = \"value\") |&gt; \n  ggplot(aes(x = value, fill = outcome)) +\n  geom_density(alpha = 0.7) +\n  facet_wrap(~ stat, scales = \"free\", ncol = 3) +\n  labs(title = \"Distribution of Pok√©mon Stats by Battle Outcome\", \n       x = \"Value\", y = \"Density\") +\n  scale_fill_manual(values = c(\"Win\" = \"#4daf4a\", \"Loss\" = \"#e41a1c\")) +\n  plot_aes\n\n\n\n\n\n\n\n\n\n\nComparing Relations between variables and outcomes\nThis plot shows how different Pok√©mon stats relate to each other and to winning or losing a battle. The diagonal panels show how each stat is distributed for winners (green) and losers (red). The lower panels show relationships between pairs of stats, with trendlines and points colored by outcome. The upper panels give the strength of the relationship between each pair of stats. Look for where the green and red separate‚Äîthose are the stats or stat combinations most associated with winning or losing.\n\n# Define your color palette\nmy_colors &lt;- c(\"Win\" = \"#4daf4a\", \"Loss\" = \"#e41a1c\")\n\ndf_small %&gt;%\n  dplyr::select(3:12, -type, winner) %&gt;%\n  rename(outcome = winner) |&gt; \n  ggpairs(\n    columns = 1:9,  # Excludes winner column from variables\n    mapping = aes(color = outcome, alpha = 0.2),\n    lower = list(\n      continuous = wrap(\"smooth\", method = \"lm\", se = FALSE)\n    ),\n    upper = list(\n      continuous = wrap(\"cor\", size = 3, color = \"black\")\n    ),\n    diag = list(\n      continuous = function(data, mapping, ...) {\n        ggally_densityDiag(data = data, mapping = mapping, ...) +\n          scale_fill_manual(values = my_colors)\n      }\n    )\n  ) +\n  scale_color_manual(values = my_colors) +\n  theme(\n    axis.text = element_text(size = 6),\n    strip.text = element_text(size = 8),\n    legend.position = \"top\"\n  ) + plot_aes"
  },
  {
    "objectID": "posts/Stats-Project/Stats-project.html#write-functions-and-prep-for-sca-analysis",
    "href": "posts/Stats-Project/Stats-project.html#write-functions-and-prep-for-sca-analysis",
    "title": "Final Project: Prediciting Head to Head Pok√©mon Wins with Multi-level Binary Logistic Regression",
    "section": "Write functions and prep for SCA Analysis",
    "text": "Write functions and prep for SCA Analysis\nBefore we get into the nittygritty of running analyses, we need to define some helper functions for SCA. The first one is a function to run the binomial logistic regression model. The second one is a function to extract the r-squared values from the model.\n\n### write binomial logistic regression function to pass to specr\nglmer_binomial &lt;- possibly(\n  function(formula, data) {\n    require(lme4)\n    require(broom.mixed)\n    glmer(formula,\n          data,\n          family = binomial(link = \"logit\"),\n          control = glmerControl(optimizer = \"bobyqa\"))\n  },\n  otherwise = NULL\n)\n\ntidy_new &lt;- function(x) {\n  fit &lt;- broom::tidy(x, conf.int = TRUE)\n  r2_vals &lt;- tryCatch(\n    performance::r2(x),\n    error = function(e) NULL\n  )\n  r2_marginal &lt;- NA\n  r2_conditional &lt;- NA\n  \n  if (!is.null(r2_vals)) {\n    if (\"R2_marginal\" %in% names(r2_vals)) {\n      # Mixed models: store Marginal and Conditional R2\n      r2_marginal &lt;- r2_vals$R2_marginal\n      r2_conditional &lt;- r2_vals$R2_conditional\n    } else if (\"R2\" %in% names(r2_vals)) {\n      # Simple models: store R2 in marginal, NA in conditional\n      r2_marginal &lt;- r2_vals$R2\n    }\n  }\n  fit$res &lt;- list(x)\n  fit$r2_marginal &lt;- r2_marginal\n  fit$r2_conditional &lt;- r2_conditional\n  return(fit)\n}"
  },
  {
    "objectID": "posts/Stats-Project/Stats-project.html#set-up-the-specifications",
    "href": "posts/Stats-Project/Stats-project.html#set-up-the-specifications",
    "title": "Final Project: Prediciting Head to Head Pok√©mon Wins with Multi-level Binary Logistic Regression",
    "section": "Set up the specifications",
    "text": "Set up the specifications\nThe Specr package allows us to set up the specifications for the models we want to run. We will set up the syntax for the models we want to run, including the variables we want to include in the model and the random effects. We will also set up a function to extract the results from the models.\nThe model we are trying to specify is winner ~ Predictors + (1 | challenger).\n\n\n\n\n\n\nüí° In this case, we are including a random slope for the challenger variable. This means that we are allowing the effect of the challenger variable to vary across different levels of the data. This is important because it allows us to account for the fact that different challengers may have different effects on the outcome of the battle.\n\n\n\nHere is a brief breakdown of the different arguments\n\n\n\n\n\n\n\ndata: The data frame containing the data to be analyzed.\nx: The independent variables to be included in the model.\ny: The dependent variable to be predicted.\nmodel: The type of model to be used. In this case, we are using a binomial logistic regression model, which we specified earlier\ncontrols: The control variables to be included in the model. These are the variables that we want to control for in the analysis.\nadd_to_formula: The random effects to be included in the model. In this case, we are including a random slope for the challenger variable.\nfun1: The function to be used to extract the results from the model. In this case, we are using the broom.mixed::tidy() function to extract the results.\nfun2: The function to be used to extract the r-squared values from the model. In this case, we are using the tidy_new() function we defined earlier.\n\n\n\n\n\n### generate the different models\nspecs = specr::setup(\n  data = df_small_scaled,\n  x = c(\"height\", \"weight\",\"attack\", \"defense\", \n        \"s_attack\", \"s_defense\", \"speed\"),\n  y = c('winner'),\n  model = c('glmer_binomial'),\n  controls = c(\"height\", \"weight\",\"attack\", \"defense\", \n        \"s_attack\", \"s_defense\", \"speed\",\"hp\"),\nadd_to_formula = \"(1 | challenger) \",  # Random slope\nfun1 = function(x) broom.mixed::tidy(x, conf.int = TRUE),\nfun2 = tidy_new\n \n)"
  },
  {
    "objectID": "posts/Stats-Project/Stats-project.html#define-the-formulas",
    "href": "posts/Stats-Project/Stats-project.html#define-the-formulas",
    "title": "Final Project: Prediciting Head to Head Pok√©mon Wins with Multi-level Binary Logistic Regression",
    "section": "Define the formulas",
    "text": "Define the formulas\nNow that we have set up the specifications, we can define the formulas for the models we want to run. The specr package allows us to define the formulas for the models we want to run and extract the results in a tidy format. Use the table below to inspect the various models we aim to run.\n\nspecs$specs &lt;- specs$specs %&gt;%\n  mutate(\n    controls_sorted = sapply(strsplit(as.character(controls), \",\"), function(x) paste(sort(trimws(x)), collapse = \",\"))\n  ) %&gt;%\n  distinct(x, y, model, controls_sorted, .keep_all = TRUE) %&gt;%  # REMOVE add_to_formula\n  dplyr::select(-controls_sorted)\n\n\nspecs$specs |&gt; \n  dplyr::select(x, y, controls,formula) |&gt;\n  DT::datatable(\n    options = list(\n      pageLength = 10,\n      autoWidth = TRUE,\n      columnDefs = list(list(width = '200px', targets = \"_all\"))\n    ),\n    rownames = FALSE\n  )"
  },
  {
    "objectID": "posts/Stats-Project/Stats-project.html#execute-the-analyses-in-parallel-using-furrr",
    "href": "posts/Stats-Project/Stats-project.html#execute-the-analyses-in-parallel-using-furrr",
    "title": "Final Project: Prediciting Head to Head Pok√©mon Wins with Multi-level Binary Logistic Regression",
    "section": "Execute the Analyses in parallel using furrr",
    "text": "Execute the Analyses in parallel using furrr\nNow that we have set up the specifications and defined the formulas, we can run the models.\nThe specr package allows us to run the models in parallel and extract the results in a tidy format, we‚Äôll utilize furrr to run our jobs in parallel to speed up the process. We‚Äôll also cache our output as a .RDS file, so each time we run the code, it won‚Äôt have to re-run the models.\n\nmodel_path &lt;- file.path(\"~/Library/CloudStorage/GoogleDrive-sm9518@princeton.edu/My Drive/Classes/Stats-blog/posts/final-project/models/sca_mode.rds\") # load in the model\n\nif (!file.exists(model_path)) { # if the file doesn't exist, then execute the code\n  specs &lt;- readRDS(model_path)\n  plan() # check what plan we have\n  opts &lt;- furrr_options(\n    globals = list(glmer_binomial = glmer_binomial) # tell the code we wanna use glmer \n  )\n  plan(strategy = multisession, workers = 6) # switch to multisession plan to make this run faster\n  results &lt;- specr(\n    specs,\n    .options = opts,   # Pass opts to specr\n    .progress = TRUE\n  )\n  plan(sequential) # switch back to sequential once done running\n  saveRDS(results, model_path)\n} else { # if the file exists, then load it in\n  results &lt;- readRDS(model_path)\n}"
  },
  {
    "objectID": "posts/Stats-Project/Stats-project.html#view-the-plots",
    "href": "posts/Stats-Project/Stats-project.html#view-the-plots",
    "title": "Final Project: Prediciting Head to Head Pok√©mon Wins with Multi-level Binary Logistic Regression",
    "section": "View the Plots",
    "text": "View the Plots\nWe can view our results using the plot function from specr. This simplest way to visualize most of the information contained in the results dataframe produced by our analyses. Briefly, the first plot shows the odds ratios for each model, while the second plot shows the specifications used in each model. The odds ratios are plotted on a log scale, and the confidence intervals are shown as error bars. The second plot shows the specifications used in each model, with the x-axis showing the different specifications and the y-axis showing the number of models that used that specification.\nGiven that we have several hundred unique models this graph gets kinda crazy to look at. You can zoom in on the plot to see the details. We‚Äôll walk through two other ways to extract information from our results below.\n\np1 &lt;- plot(results, \n           type = \"curve\",\n           ci = T, \n           ribbon = F) +\n  geom_hline(yintercept = 0, \n             linetype = \"dashed\", \n             color = \"black\") +\n  labs(x = \"\", y = \"Odds Ratio\") + plot_aes\n\np2 &lt;- plot(results, \n           type = \"choices\",\n           choices = c(\"x\", \"y\", \"controls\")) +\n  labs(x = \"specifications (ranked)\") +\n  plot_aes + \n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    axis.text.y = element_text(size = 5),\n    axis.ticks.x = element_blank(),\n    axis.ticks.y = element_blank(),\n    axis.line.x = element_line(\"black\", size = .5),\n    axis.line.y = element_line(\"black\", size = .5)\n  )\n\nplot_grid(\n  p1, p2,\n  ncol = 1,           \n  align = \"v\",          \n  axis = \"rbl\",          \n  rel_heights = c(.60, 2.25)  \n)"
  },
  {
    "objectID": "posts/Stats-Project/Stats-project.html#individually-inspect-the-top-n-models",
    "href": "posts/Stats-Project/Stats-project.html#individually-inspect-the-top-n-models",
    "title": "Final Project: Prediciting Head to Head Pok√©mon Wins with Multi-level Binary Logistic Regression",
    "section": "Individually Inspect the top N-Models",
    "text": "Individually Inspect the top N-Models\nNow that we used specr(), we can summarize individual specifications by using broom::tidy() and broom::glance(). For most cases, this provides a sufficient and appropriate summary of the relationship of interest and model characteristics. Sometimes, however, it might be useful to investigate specific models in more detail or to investigate a specific parameter that is not provided by the two functions (e.g., r-square or variance accounted for by the model).\n\nInspect the significant models\nFirst, we‚Äôll look at just the significant models (i.e., p &lt; 0.05). This is done by filtering the results dataframe to only include significant models. We can then use the DT package to create an interactive table that allows us to sort and filter the data.\n\nmodels &lt;- results %&gt;% \n  as_tibble() %&gt;% \n  dplyr::select(formula, x, y, estimate, std.error, p.value, conf.low, conf.high) %&gt;% \n  filter(p.value &lt; 0.051) %&gt;%  # keep only significant models\n  mutate(\n    estimate = round(estimate, 3),\n    std.error = round(std.error, 3),\n    p.value = round(p.value, 3),\n    conf.low = round(conf.low, 3),\n    conf.high = round(conf.high, 3)\n  ) %&gt;%\n  arrange(desc(abs(estimate)))\n\nmodels |&gt;\n  DT::datatable(\n    options = list(\n      pageLength = 10,\n      autoWidth = TRUE,\n      columnDefs = list(list(targets = \"_all\"))\n    ),\n    rownames = FALSE\n  )\n\n\n\n\n\n\n\nHow does R-squared change with different models?\nWe can also evaluate the best model by looking at the conditional r-square value. We start by ranking the models by their conditional r-square value and then plotting the results. This will allow us to see which models are the best predictors of the outcome.\nFrom the results below, we can see that we can account for over 50% of the variance in the outcome using just the challenger Pokemon‚Äôs stats. This is a pretty good result, and it suggests that we can use these stats to predict the outcome of a battle. However, we still don‚Äôt quite know what the recipe for the best model is yet.\n\nbest_model &lt;- results %&gt;% \n  as_tibble() %&gt;% \n  dplyr::select(formula, x, y, estimate, std.error, p.value, conf.low, conf.high,fit_r2_conditional) %&gt;% \n  filter(p.value &lt; 0.051) %&gt;%  # keep only significant models\n  mutate(\n    estimate = round(estimate, 3),\n    std.error = round(std.error, 3),\n    p.value = round(p.value, 3),\n    conf.low = round(conf.low, 3),\n    conf.high = round(conf.high, 3)\n  ) \n\nbest_model %&gt;%\n  arrange(fit_r2_conditional) %&gt;%\n  mutate(rank = 1:n()) %&gt;%\n  ggplot(aes(x = rank, y = fit_r2_conditional)) +\n  geom_line(color = \"#ADA7C9\", size = 0.85) +  # smooth teal-ish line\n  geom_point(size = 1.5, alpha = 0.7, color = \"#4D4861\") +  # darker small points\n  theme_minimal(base_family = \"Futura Medium\") +  # match your font\n  theme(\n    panel.grid.minor = element_blank(),\n    panel.grid.major.x = element_blank(),\n    axis.line = element_line(color = \"black\", size = 0.5),\n    axis.ticks = element_line(color = \"black\"),\n    axis.text = element_text(color = \"black\"),\n    strip.text = element_blank()\n  ) +\n  labs(\n    x = \"Model Rank\",\n    y = \"Conditional R¬≤\"\n  ) +\n  plot_aes\n\n\n\n\n\n\n\n\n\n\nWhat seems to be the best model?\nNow that we have a sense of the best model, we can plot the results using ggplot to create a bar graph that shows us how much variance each of the top 50 models accounts for.\n\nbest_model %&gt;%\n  arrange(desc(fit_r2_conditional), desc(estimate)) %&gt;%\n  head(50) %&gt;%\n  mutate(rank = 1:n()) %&gt;%\n  ggplot(aes(x = factor(rank), \n             y = fit_r2_conditional, \n             fill = fit_r2_conditional)) +  # Use fit_r2_conditional for color fill\n  geom_col() +\n  geom_text(aes(label = formula), \n            vjust = -0.5, \n            size = 3, \n            angle = 90) +\n  scale_fill_gradient(low = \"#ee9b00\", high = \"#c44536\") +  # Gradient from low to high values\n  plot_aes + \n  theme(\n    strip.text = element_blank(),\n    axis.line = element_line(color = \"black\", size = .5),\n    axis.text = element_text(color = \"black\"),\n    axis.text.x = element_text(angle = 45, hjust = 1),  # Rotate x-axis labels by 45 degrees\n    legend.position = \"none\"\n  ) +\n  labs(x = \"Model Rank\", y = \"Conditional R¬≤\") +\n  ylim(0, 0.55)\n\n\n\n\n\n\n\n\nBased on what our graph tells us, the best model is (1 | challenger) + s_defense. This model accounts for 55% of the variance in the outcome, which is a pretty good result. However, it‚Äôs important to note that this is a pretty simple model and there are likely other factors that could be included to improve the model. For example, we could include the opponent‚Äôs stats or other variables that might be relevant to the outcome of the battle. If anything, this goes to show how balanced of a meta Pokemon has.\nThanks for following along!\n\n\n\nIf you‚Äôd like to learn more about SCA, I‚Äôd recommend checking out ‚ú®Dr.¬†Dani Cosme‚Äôs ‚ú® website. She‚Äôs an amazing person, teacher, and has a ton of great resources on SCA and other statistical methods in R. I especially recommend this reproducibililty workshop."
  },
  {
    "objectID": "posts/Federal research funding cuts will stall scientific progress, hurt Texas students/Federal research funding cuts will stall scientific progress, hurt Texas students.html",
    "href": "posts/Federal research funding cuts will stall scientific progress, hurt Texas students/Federal research funding cuts will stall scientific progress, hurt Texas students.html",
    "title": "Federal research funding cuts will stall scientific progress, hurt Texas students",
    "section": "",
    "text": "This piece was published as an Op-ed in the San Antonio Express News\nScientific progress in the United States faces a series of threats. These disruptions have slashed federal research funding; upended the scientific process; dismantled diversity, equity and inclusion ‚Äî DEI ‚Äî initiatives; and endangered the careers of future and current scientists.\nIn particular, the federal government has frozen billions in funding for the National Institutes of Health and the National Science Foundation ‚Äî both of which provide substantial medical and economic benefits to San Antonio and Texas.\nLast year, the NIH awarded nearly $2 billion in funding to Texan institutes, which supported more than 30,000 Texan jobs and generated more than $6 billion in economic activity.\nAs a scientist, I am deeply concerned about these funding cuts. I strongly believe in the direct and indirect opportunities that science provides to improve the lives of our community members.\nI am a Mexican American who was born and raised on San Antonio‚Äôs West Side, where programs like the Pre-Freshman Engineering Program, or PREP, gave me early exposure to careers in science and laid the foundation for my academic journey.\nToday, I am fortunate enough to be a psychology doctoral student at Princeton University, where I am conducting research showing how to identify individuals struggling with poor mental health by examining patterns in their language use.\nPrograms like PREP provided my first introduction to research, which was further developed in labs at Texas State University, the University of Texas at Austin and the University of Pennsylvania ‚Äî all institutions supported by grants from the NIH and NSF.\nPrograms like PREP, often labeled as ‚ÄúDEI initiatives,‚Äù are not about exclusion. They are about giving everyone a shot at the American Dream. They ensure young people without built-in academic connections or financial resources have opportunities to pursue careers in science.\nWithout these programs, countless students ‚Äî regardless of race, gender or political affiliation ‚Äî will lose their chance to break into fields that shape our nation‚Äôs future.\nStripping funding from anything perceived as ‚ÄúDEI-adjacent‚Äù harms us all. It reduces available jobs in the state, freezes life-changing research and shuts the door on talented, hardworking students.\nTo make matters worse, recent government budget cuts have slashed funding for universities, including critical ‚Äúindirect costs‚Äù that fund lab space, technical support, and salaries for scientists and staff.\nUniversities across the country, including the University of Texas at San Antonio, have already begun reducing graduate admissions. This disruption will shrink the pipeline of trained scientists, limit opportunities for young San Antonians, and jeopardize scientific progress in Texas and beyond.\nDue to decades of federally funded research, we have breakthroughs like revolutionary cancer treatments and lifesaving vaccines. Similar advancements have been made in our ability to detect mental health issues with language and provide more personalized support ‚Äî progress that can save countless lives.\nThese advancements depend on continued support from institutions like the NIH and NSF, which drive our economy, research and the training of future scientists.\nPrograms that provide early exposure to science ‚Äî especially for underrepresented students ‚Äî ensure that the next generation is prepared to tackle issues like the mental health epidemic.\nCutting funding for research and training will stall progress and limit opportunities for young minds. Now more than ever, we must fight to protect science and its future to build a healthier, more resilient society for everyone.\n\nAbout the Author\nSteven Mesquiti was born and raised in San Antonio‚Äôs West Side. He completed his undergraduate studies at Southwestern University, has a master‚Äôs degree from Texas State University and is a doctoral student at Princeton University."
  },
  {
    "objectID": "posts/LLM on HPC/LLM-to-HPC.html",
    "href": "posts/LLM on HPC/LLM-to-HPC.html",
    "title": "LLM to HPC Tutorial",
    "section": "",
    "text": "This guide walks you through configuring your environment, authenticating access, and downloading the LLaMA 3 models from Hugging Face on the Adroit HPC system. It assumes you have basic familiarity with command line, Python, and HPC usage.\nThis process is infinitely easier if you have connected VSCode to the adroit cluster. Here is some info on that. IT also runs help sessions on this, which are very useful.\n\n\nBy default, Hugging Face stores downloaded models in your home directory (e.g., /home/username/.cache/huggingface), which may have limited storage on HPC systems. Redirect the cache to your scratch directory for ample space.\nYou can do that by using the checkquota command in the terminal to find out how much space you have in your scratch directory.\n\nSet the environment variable HF_HOME to your scratch directory:\n\nOn the Adroit login node, run this command to append the export statement to your .bashrc:\necho \"export HF_HOME=/scratch/network/$USER/.cache/huggingface/\" &gt;&gt; $HOME/.bashrc\n\nReload your shell configuration:\n\nsource ~/.bashrc\n\nVerify the variable is set:\n\necho $HF_HOME\nThe excpected output should be:\n/scratch/network/&lt;YourNetID&gt;/.cache/huggingface/\n\n\n\nMeta requires users to accept a license and gain explicit access to the LLaMA 3 models on Hugging Face. So, this means you‚Äôll need sign up for a Hugging Face account and request access to the LLaMA 3 models.\n\nGo to the LLaMA 3 model page on Hugging Face: https://huggingface.co/meta-llama/Llama-3.1-8B (or whatever model you want access to)\nLog in or create a Hugging Face account if you haven‚Äôt already.\nAccept the model license terms: Click the ‚ÄúAccess repository‚Äù button and agree to the license to request access.\nWait for access to be granted. This should be relatively quick, but may take a few minutes to a few hours depending on demand.\n\n\n\n\nOnce access is granted, authenticate your HPC environment to allow downloading protected models.\n\nLog in to Hugging Face CLI:\n\nOn the Adroit login node, run the following command:\nhuggingface-cli login\n\nEnter your Hugging Face token:\n\nYou will be prompted to enter your Hugging Face access token. You can find this token in your Hugging Face account settings under ‚ÄúAccess Tokens‚Äù. Copy and paste it into the terminal when prompted. Make sure not to share this with anyone since this is a personal access token that allows downloading models.\n\n\n\nNow that you have authenticated, you can download the LLaMA 3 model to your scratch directory.\n\nCreate a Python script download_llama3.py with this content:\n\nMake sure to replace meta-llama/Llama-3.1-8B with the specific model you want\nto download if different. Also, make sure you have transformers installed in your Python environment.\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\n\nmodel_id = \"meta-llama/Llama-3.1-8B\"\ncache_path = \"/scratch/network/sm9518/.cache/huggingface\"  # replace with your actual NetID\n\n# Download model and tokenizer to cache\nAutoTokenizer.from_pretrained(model_id, cache_dir=cache_path)\nAutoModelForCausalLM.from_pretrained(model_id, cache_dir=cache_path)\n\nprint(f\"{model_id} Downloaded Successfully! to {cache_path}\")\n\nRun the script on the login node:\n\npython download_llama3.py\n\nThis will download all necessary model files into your scratch cache directory set by HF_HOME.\n\n\n\n\nNow that you have downloaded the LLaMA 3 model to your scratch directory, you can run inference on an HPC compute node.\n\n\nSave the following code to /scratch/network/$USER/python_test/run_test_llama.py. This script loads the model and runs a short text generation example using the transformers pipeline API.\nfrom transformers import pipeline\nimport torch\nimport os\n\nprint(f\"CUDA Available: {torch.cuda.is_available()}\")\n\nif not torch.cuda.is_available():\n    raise ValueError(\n        \"CUDA is not available. Make sure you are running this on a GPU node. \"\n        \"For example, run with Slurm requesting GPU:\\n\\n\"\n        \"\\tsalloc -t 0:10:00 --ntasks=1 --gres=gpu:1 python run_test_llama.py\"\n    )\n\nmodel_path = \"/scratch/network/$USER/.cache/huggingface/models--meta-llama--Llama-3.1-8B/snapshots/d04e592bb4f6aa9cfee91e2e20afa771667e1d4b\"\n\nprint(\"CUDA_VISIBLE_DEVICES =\", os.environ.get(\"CUDA_VISIBLE_DEVICES\"))\n\npipe = pipeline(\"text-generation\", model=model_path, tokenizer=model_path)\n\nprompt = \"You are an expert psychologist. Tell me something interesting about psychology regarding Erik Nook's research:\"\noutput = pipe(prompt, max_new_tokens=50)\n\nprint(\"\\nModel output:\\n\", output)\n\nMake sure to replace $USER in the path with your actual NetID or use a variable if running programmatically.\n\n\n\n\nThis Slurm batch script requests one A100 GPU on the Adroit cluster and runs the above Python test script.\n#!/bin/bash\n#SBATCH --job-name=llama3-textgen           # Job name\n#SBATCH --nodes=1                           # Use one node\n#SBATCH --ntasks=1                          # One task\n#SBATCH --cpus-per-task=1                   # One CPU core\n#SBATCH --mem=36G                          # Memory request # can be ess\n#SBATCH --gres=gpu:1                        # Request 1 GPU\n#SBATCH --time=00:10:00                     # Max runtime (adjust as needed)\n#SBATCH --constraint=a100                   # Use A100 GPU\n#SBATCH --nodelist=adroit-h11g1             # Run on node with free GPUs\n#SBATCH --mail-type=ALL                     # Email on start, end, fail\n#SBATCH --mail-user=sm9518@princeton.edu   # Your email\n\nmodule purge\nmodule load anaconda3/2024.6\nmodule load cudatoolkit/11.8 \n\nsource activate talkspaceMADS\n\ncd /scratch/network/$USER/python_test\n\necho \"Job started at $(date)\"\n\nexport PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True\n\npython run_test_llama.py\n\necho \"Job completed at $(date)\"\n\nüí° Check GPU Node Usage Before Selecting a Node or GPU.\nBefore submitting your job or manually specifying a GPU node (e.g., with #SBATCH --nodelist=adroit-h11g1).\nIt‚Äôs a good idea to check which nodes and GPUs have free memory or are under low load. Otherwise, your job might be assigned to a GPU that is already fully used, causing CUDA out-of-memory errors.\n\nOn Adroit, you can use commands like these from the login node to check GPU availability:\n# Show GPU status and free GPUs per node \nshownodes -p gpu\nIf you don‚Äôt specify a node, Slurm will pick one for you, but it might not always be the best choice if GPUs on that node are busy."
  },
  {
    "objectID": "posts/LLM on HPC/LLM-to-HPC.html#step-1-configure-the-hugging-face-cache-directory",
    "href": "posts/LLM on HPC/LLM-to-HPC.html#step-1-configure-the-hugging-face-cache-directory",
    "title": "LLM to HPC Tutorial",
    "section": "",
    "text": "By default, Hugging Face stores downloaded models in your home directory (e.g., /home/username/.cache/huggingface), which may have limited storage on HPC systems. Redirect the cache to your scratch directory for ample space.\nYou can do that by using the checkquota command in the terminal to find out how much space you have in your scratch directory.\n\nSet the environment variable HF_HOME to your scratch directory:\n\nOn the Adroit login node, run this command to append the export statement to your .bashrc:\necho \"export HF_HOME=/scratch/network/$USER/.cache/huggingface/\" &gt;&gt; $HOME/.bashrc\n\nReload your shell configuration:\n\nsource ~/.bashrc\n\nVerify the variable is set:\n\necho $HF_HOME\nThe excpected output should be:\n/scratch/network/&lt;YourNetID&gt;/.cache/huggingface/"
  },
  {
    "objectID": "posts/LLM on HPC/LLM-to-HPC.html#step-2-get-authentication-access-from-meta-required-for-llama-models",
    "href": "posts/LLM on HPC/LLM-to-HPC.html#step-2-get-authentication-access-from-meta-required-for-llama-models",
    "title": "LLM to HPC Tutorial",
    "section": "",
    "text": "Meta requires users to accept a license and gain explicit access to the LLaMA 3 models on Hugging Face. So, this means you‚Äôll need sign up for a Hugging Face account and request access to the LLaMA 3 models.\n\nGo to the LLaMA 3 model page on Hugging Face: https://huggingface.co/meta-llama/Llama-3.1-8B (or whatever model you want access to)\nLog in or create a Hugging Face account if you haven‚Äôt already.\nAccept the model license terms: Click the ‚ÄúAccess repository‚Äù button and agree to the license to request access.\nWait for access to be granted. This should be relatively quick, but may take a few minutes to a few hours depending on demand."
  },
  {
    "objectID": "posts/LLM on HPC/LLM-to-HPC.html#step-3-log-in-to-hugging-face-cli-on-hpc",
    "href": "posts/LLM on HPC/LLM-to-HPC.html#step-3-log-in-to-hugging-face-cli-on-hpc",
    "title": "LLM to HPC Tutorial",
    "section": "",
    "text": "Once access is granted, authenticate your HPC environment to allow downloading protected models.\n\nLog in to Hugging Face CLI:\n\nOn the Adroit login node, run the following command:\nhuggingface-cli login\n\nEnter your Hugging Face token:\n\nYou will be prompted to enter your Hugging Face access token. You can find this token in your Hugging Face account settings under ‚ÄúAccess Tokens‚Äù. Copy and paste it into the terminal when prompted. Make sure not to share this with anyone since this is a personal access token that allows downloading models."
  },
  {
    "objectID": "posts/LLM on HPC/LLM-to-HPC.html#step-4-download-the-llama-3-model-on-the-login-node",
    "href": "posts/LLM on HPC/LLM-to-HPC.html#step-4-download-the-llama-3-model-on-the-login-node",
    "title": "LLM to HPC Tutorial",
    "section": "",
    "text": "Now that you have authenticated, you can download the LLaMA 3 model to your scratch directory.\n\nCreate a Python script download_llama3.py with this content:\n\nMake sure to replace meta-llama/Llama-3.1-8B with the specific model you want\nto download if different. Also, make sure you have transformers installed in your Python environment.\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\n\nmodel_id = \"meta-llama/Llama-3.1-8B\"\ncache_path = \"/scratch/network/sm9518/.cache/huggingface\"  # replace with your actual NetID\n\n# Download model and tokenizer to cache\nAutoTokenizer.from_pretrained(model_id, cache_dir=cache_path)\nAutoModelForCausalLM.from_pretrained(model_id, cache_dir=cache_path)\n\nprint(f\"{model_id} Downloaded Successfully! to {cache_path}\")\n\nRun the script on the login node:\n\npython download_llama3.py\n\nThis will download all necessary model files into your scratch cache directory set by HF_HOME."
  },
  {
    "objectID": "posts/LLM on HPC/LLM-to-HPC.html#step-5-test-the-downloaded-model",
    "href": "posts/LLM on HPC/LLM-to-HPC.html#step-5-test-the-downloaded-model",
    "title": "LLM to HPC Tutorial",
    "section": "",
    "text": "Now that you have downloaded the LLaMA 3 model to your scratch directory, you can run inference on an HPC compute node.\n\n\nSave the following code to /scratch/network/$USER/python_test/run_test_llama.py. This script loads the model and runs a short text generation example using the transformers pipeline API.\nfrom transformers import pipeline\nimport torch\nimport os\n\nprint(f\"CUDA Available: {torch.cuda.is_available()}\")\n\nif not torch.cuda.is_available():\n    raise ValueError(\n        \"CUDA is not available. Make sure you are running this on a GPU node. \"\n        \"For example, run with Slurm requesting GPU:\\n\\n\"\n        \"\\tsalloc -t 0:10:00 --ntasks=1 --gres=gpu:1 python run_test_llama.py\"\n    )\n\nmodel_path = \"/scratch/network/$USER/.cache/huggingface/models--meta-llama--Llama-3.1-8B/snapshots/d04e592bb4f6aa9cfee91e2e20afa771667e1d4b\"\n\nprint(\"CUDA_VISIBLE_DEVICES =\", os.environ.get(\"CUDA_VISIBLE_DEVICES\"))\n\npipe = pipeline(\"text-generation\", model=model_path, tokenizer=model_path)\n\nprompt = \"You are an expert psychologist. Tell me something interesting about psychology regarding Erik Nook's research:\"\noutput = pipe(prompt, max_new_tokens=50)\n\nprint(\"\\nModel output:\\n\", output)\n\nMake sure to replace $USER in the path with your actual NetID or use a variable if running programmatically.\n\n\n\n\nThis Slurm batch script requests one A100 GPU on the Adroit cluster and runs the above Python test script.\n#!/bin/bash\n#SBATCH --job-name=llama3-textgen           # Job name\n#SBATCH --nodes=1                           # Use one node\n#SBATCH --ntasks=1                          # One task\n#SBATCH --cpus-per-task=1                   # One CPU core\n#SBATCH --mem=36G                          # Memory request # can be ess\n#SBATCH --gres=gpu:1                        # Request 1 GPU\n#SBATCH --time=00:10:00                     # Max runtime (adjust as needed)\n#SBATCH --constraint=a100                   # Use A100 GPU\n#SBATCH --nodelist=adroit-h11g1             # Run on node with free GPUs\n#SBATCH --mail-type=ALL                     # Email on start, end, fail\n#SBATCH --mail-user=sm9518@princeton.edu   # Your email\n\nmodule purge\nmodule load anaconda3/2024.6\nmodule load cudatoolkit/11.8 \n\nsource activate talkspaceMADS\n\ncd /scratch/network/$USER/python_test\n\necho \"Job started at $(date)\"\n\nexport PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True\n\npython run_test_llama.py\n\necho \"Job completed at $(date)\"\n\nüí° Check GPU Node Usage Before Selecting a Node or GPU.\nBefore submitting your job or manually specifying a GPU node (e.g., with #SBATCH --nodelist=adroit-h11g1).\nIt‚Äôs a good idea to check which nodes and GPUs have free memory or are under low load. Otherwise, your job might be assigned to a GPU that is already fully used, causing CUDA out-of-memory errors.\n\nOn Adroit, you can use commands like these from the login node to check GPU availability:\n# Show GPU status and free GPUs per node \nshownodes -p gpu\nIf you don‚Äôt specify a node, Slurm will pick one for you, but it might not always be the best choice if GPUs on that node are busy."
  },
  {
    "objectID": "publications/analysis-of-social-media-language-reveals-the-psychological-interaction-of-three-successive-upheavals/index.html",
    "href": "publications/analysis-of-social-media-language-reveals-the-psychological-interaction-of-three-successive-upheavals/index.html",
    "title": "Analysis of social media language reveals the psychological interaction of three successive upheavals",
    "section": "",
    "text": "Abstract\nUsing social media data, the present study documents how three successive upheavals: the COVID pandemic, the Black Lives Matter (BLM) protests of 2020, and the US Supreme Court decision to overturn Roe v. Wade interacted to impact the cognitive, emotional, and social styles of people in the US. Text analyses were conducted on 45,225,895 Reddit comments from 2,451,289 users and 889,402 news headlines from four news sources. Results revealed significant shifts in language related to self-focus (e.g., first-person singular pronouns), collective-focus (e.g., first-person plural pronouns), negative emotion (anxiety and anger words), and engagement (e.g., discussion of upheaval-related topics) after each event. Language analyses captured how social justice-related upheavals (BLM, Roe v. Wade) may have affected people in different ways emotionally than those that affected them personally (COVID). The onset of COVID was related to people becoming increasingly anxious and people turned inward to focus on their personal situations. However, BLM and the overturning of Roe v. Wade aroused anger and action, as people may have looked beyond themselves to address these issues. Analysis of upheaval-related discussions captured the public‚Äôs sustained interest in BLM and COVID, whereas interest in Roe v. Wade declined relatively quickly. Shifts in discussions also showed how events interacted as people focused on only one national event at a time, with interest in other events dampening when a new event occurred. The findings underscore the dynamic nature of culturally shared events that are apparent in everyday online language use.\nCitation: Mesquiti, S., Seraj, S., Weyland, A. H., Ashokkumar, A., Boyd, R. L., Mihalcea, R., & Pennebaker, J. W. (2025). Analysis of social media language reveals the psychological interaction of three successive upheavals. Scientific Reports, 15, 5740. https://doi.org/10.1038/s41598-025-89165-z"
  },
  {
    "objectID": "publications/the-psychological-impacts-of-the-covid-19-pandemic-on-business-leadership/index.html",
    "href": "publications/the-psychological-impacts-of-the-covid-19-pandemic-on-business-leadership/index.html",
    "title": "The psychological impacts of the COVID-19 pandemic on business leadership",
    "section": "",
    "text": "Abstract\nThe COVID-19 pandemic had a profound impact on business leadership, specifically on chief executive officers (CEOs). To document the psychological impacts of the pandemic on corporate leadership, this study analyzed the language of CEOs during company quarterly earnings calls (N=19,536) one year before and after the onset of the pandemic. Following the start of lockdowns, CEOs exhibited significant language shifts. Analytic thinking declined, and their language became less technical and more personal and intuitive. CEOs also showed signs of increased cognitive load as they grappled with the pandemic‚Äôs impact on their business practices. The study observed a substantial decrease in collective-focused language (we-usage) among CEOs, indicative of disconnection from their companies. Concurrently, there was an increase in self-focused (I-usage) language, suggesting heightened preoccupation among business leaders. The observed language changes reflect the unique effect of the pandemic on CEOs, which had some notable differences compared to the general population. This study sheds light on how the COVID-19 pandemic influenced business leaders‚Äô psychological states and decision-making strategies‚Äîprocesses that have a substantial impact on a company‚Äôs performance. The findings underscore the importance of language data in understanding large-scale societal events.\nCitation: Mesquiti, S., & Seraj, S. (2023). The psychological impacts of the COVID-19 pandemic on business leadership. PLoS ONE, 18(10), e0290621. https://doi.org/10.1371/journal.pone.0290621"
  },
  {
    "objectID": "publications.html",
    "href": "publications.html",
    "title": "Publications and Preprints",
    "section": "",
    "text": "Publications and Preprints\n\n\n\n\n\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Title\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nEmpathy and helping: the role of affect in response to others‚Äô suffering\n\n\n\n\n\n\n\n\n\n\n\n\n\nAnalysis of social media language reveals the psychological interaction of three successive upheavals\n\n\n\n\n\n\n\n\n\n\n\n\n\nPredicting Psychological and Subjective Well-being through Language-based Assessment\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe psychological impacts of the COVID-19 pandemic on business leadership\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "Posts",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nFinal Project: Prediciting Head to Head Pok√©mon Wins with Multi-level Binary Logistic Regression\n\n\nPSY-504\n\n\n\nFinal-Project\n\n\nCoding\n\n\nTutorial\n\n\n\n\n\n\n\n\n\nSteven Mesquiti\n\n\n\n\n\n\n\n\n\n\n\n\nLLM to HPC Tutorial\n\n\n\n\n\n\nCoding\n\n\nTutorial\n\n\n\n\n\n\n\n\n\nSteven Mesquiti\n\n\n\n\n\n\n\n\n\n\n\n\nData-Driven Approaches to Building Equitable Language-Based Mental Health Assessments\n\n\n\n\n\n\n\n\n\n\n\nInvalid Date\n\n\nSteven\n\n\n\n\n\n\n\n\n\n\n\n\nFederal research funding cuts will stall scientific progress, hurt Texas students\n\n\n\n\n\n\nOpinion\n\n\nScience Policy\n\n\n\n\n\n\n\n\n\nMar 17, 2025\n\n\nSteven Mesquiti\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/LBA-Race-Kickoff/Presentation.html#design",
    "href": "posts/LBA-Race-Kickoff/Presentation.html#design",
    "title": "Data-Driven Approaches to Building Equitable Language-Based Mental Health Assessments",
    "section": "Design",
    "text": "Design\n\nTwo-session online longitudinal study.\n\nBaseline: open-text responses about mood, motivation, sleep (‚âà25 min) + GAD-7 + PHQ-8.\nFollow-up (1 week): repeat assessments (‚âà10 min)."
  },
  {
    "objectID": "posts/LBA-Race-Kickoff/Presentation.html#sample",
    "href": "posts/LBA-Race-Kickoff/Presentation.html#sample",
    "title": "Data-Driven Approaches to Building Equitable Language-Based Mental Health Assessments",
    "section": "Sample",
    "text": "Sample\n\nN = 1,600 (ages 18‚Äì40), balanced by race/ethnicity (White, Black, Latino, Asian). \nRecruitment platform: Online panel (e.g., Prolific) with demographic quotas."
  }
]